{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from joblib import load\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "sys.path.insert(0, '../../../../..')\n",
    "sys.path.insert(0, '../../../../../..')\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from reimplemented_approaches.proactive_conformance_checking.models import LSTMSeparateIDP\n",
    "from reimplemented_approaches.proactive_conformance_checking.training import Training\n",
    "from reimplemented_approaches.proactive_conformance_checking.data_prep_split_encode import PrefixDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoders:\n",
    "# Load prepared and encoded datasets\n",
    "train_set_dict, val_set_dict, test_set_dict = PrefixDataset.load_datasets(save_path=\"../../../data_preparation/BPIC20/separate/\")\n",
    "train_labels = sorted(train_set_dict.keys())\n",
    "print(f\"Loaded {len(train_labels)} deviation labels: {train_labels}\")\n",
    "\n",
    "encoders = load(\"../../../data_preparation/BPIC20/separate/encoders.pkl\")\n",
    "\n",
    "encoder_values = list(encoders.values())[0]\n",
    "\n",
    "activity_ids = encoder_values.get('activity_ids')\n",
    "\n",
    "activity_ids_vocab_size_with_default = len(list(activity_ids.keys())) + 1\n",
    "print(\"Activities: \", activity_ids_vocab_size_with_default)\n",
    "\n",
    "resource_ids = encoder_values.get('resource_ids')\n",
    "resource_ids_vocab_size_with_default = len(list(resource_ids.keys())) + 1\n",
    "print(\"Resources: \", resource_ids_vocab_size_with_default)\n",
    "\n",
    "month_ids = encoder_values.get('month_ids')\n",
    "month_ids_vocab_size_with_default = len(list(month_ids.keys())) + 1\n",
    "print(\"Months: \", month_ids_vocab_size_with_default)\n",
    "\n",
    "deviation_ids = encoder_values.get('deviations')\n",
    "if hasattr(deviation_ids, 'keys'):\n",
    "    number_deviations_y = len(list(deviation_ids.keys()))\n",
    "else:\n",
    "    number_deviations_y = len(deviation_ids)\n",
    "print(\"Deviation types: \", number_deviations_y)\n",
    "\n",
    "sample_label = train_labels[0]\n",
    "number_trace_attr = train_set_dict[sample_label].tensors[3].size(1)\n",
    "print(\"Number trace attributes: \", number_trace_attr)\n",
    "print(\"Example label used for shape inference:\", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d375d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding / model hyperparameters\n",
    "embedding_dim = 16\n",
    "# lstm hidden size\n",
    "lstm_hidden = 128\n",
    "# fully connected hidden\n",
    "fc_hidden = 128\n",
    "# dropout probability\n",
    "p_dropout = 0.1\n",
    "\n",
    "def build_model(num_trace_features: int, num_output_labels: int):\n",
    "    \n",
    "    return LSTMSeparateIDP(activity_vocab_size=activity_ids_vocab_size_with_default,\n",
    "                           resource_vocab_size=resource_ids_vocab_size_with_default,\n",
    "                           month_vocab_size=month_ids_vocab_size_with_default,\n",
    "                           num_trace_features=num_trace_features,\n",
    "                           num_output_labels=num_output_labels,\n",
    "                           # used from paper:\n",
    "                           embedding_dim=embedding_dim,\n",
    "                           lstm_hidden=lstm_hidden,\n",
    "                           fc_hidden=fc_hidden,\n",
    "                           dropout=p_dropout,\n",
    "                           device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "epochs = 300  # 300 with early stopping (20% val from all train)\n",
    "learning_rate = 0.0001\n",
    "\n",
    "trained_label_models = {}\n",
    "training_histories = {}\n",
    "\n",
    "# Build an train for each label in the deviation set an own LSTM\n",
    "for label in train_labels:\n",
    "    \n",
    "    print(f\"\\nTraining deviation label: {label}\")\n",
    "    train_set = train_set_dict[label]\n",
    "    val_set = val_set_dict[label]\n",
    "    num_trace_features = train_set.tensors[3].size(1)\n",
    "    # Binary prediction: Output head must have size 2: one for true, one for false.\n",
    "    num_output_labels = train_set.tensors[4].size(1) + 1\n",
    "    \n",
    "    model = build_model(num_trace_features=num_trace_features, num_output_labels=num_output_labels)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer_values = {\"optimizer\": optimizer,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"mini_batches\": batch_size,\n",
    "                        \"shuffle\": shuffle}\n",
    "    \n",
    "    training = Training(model=model,\n",
    "                        train_set=train_set,\n",
    "                        val_set=val_set,\n",
    "                        optimizer_values=optimizer_values,\n",
    "                        device=device,\n",
    "                        loss_mode=\"separate\",\n",
    "                        saving_path=f\"./LSTM_separate_IDP_{label}.pkl\")\n",
    "    \n",
    "    history = training.train()\n",
    "    \n",
    "    training_histories[label] = history\n",
    "    trained_label_models[label] = f\"./LSTM_separate_IDP_{label}.pkl\"\n",
    "\n",
    "print(\"\\nFinished training all labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_controlled_proactive_conformance_chec-7RbHgjHV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
