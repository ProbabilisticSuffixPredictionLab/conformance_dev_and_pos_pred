{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "sys.path.insert(0, '../../../../..')\n",
    "sys.path.insert(0, '../../../../../..')\n",
    "\n",
    "from reimplemented_approaches.proactive_conformance_checking.data_prep_split_encode import DeviationLabeling, TrainTestSplit, Undersampling, PrefixDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97acd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading:\n",
    "name_event_log = \"Repair\"\n",
    "path_event_log = \"../../../../../../../data/artificial/repair_shop_event_log.csv\"\n",
    "path_process_model = \"../../../../../../../data/process_models/Repair.bpmn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes:\n",
    "# Load the event log as pandas dataframe. Get all attributes in the log:\n",
    "df = pd.read_csv(path_event_log)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation and labelling\n",
    "dl = DeviationLabeling(log_name=name_event_log,\n",
    "                       path_event_log=path_event_log,\n",
    "                       path_process_model=path_process_model,\n",
    "                       label_strategy='collective')\n",
    "\n",
    "# collective\n",
    "df_labeled_deviations, encoders = dl.generate_individual_labels(trace_attr=[], conf_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_ids = encoders['activity_ids']\n",
    "print(\"Activity ids: \" ,act_ids)\n",
    "print(\"\\n\")\n",
    "\n",
    "res_ids = encoders['resource_ids']\n",
    "print(\"Reource ids: \", res_ids)\n",
    "print(\"\\n\")\n",
    "\n",
    "months = encoders['month_ids']\n",
    "print(\"Months: \", months)\n",
    "print(\"\\n\")\n",
    "\n",
    "deviations = encoders['deviations']\n",
    "print(\"Deviations: \", deviations)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared dataframe as .csv\n",
    "os.makedirs(\".\", exist_ok=True)\n",
    "csv_path_collective = os.path.join(\"./prefix_deviations.csv\")\n",
    "df_labeled_deviations.to_csv(csv_path_collective, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "tts = TrainTestSplit(df_labled_deviations=df_labeled_deviations,\n",
    "                     label_strategy = \"collective\")\n",
    "\n",
    "train_df, val_df, test_df = tts.data_split(val_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad24e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling train set\n",
    "u = Undersampling(train_data=train_df, \n",
    "                  list_dynamic_cols=['activities', 'resources', 'months'],\n",
    "                  label_strategy='collective')\n",
    "\n",
    "train_df, y_no_true_class = u.one_sided_selection_undersampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0987f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoder ids for all attributes in the dataframe:\n",
    "y_columns = cols = [c for c in train_df.columns if c.startswith(\"y_\")]\n",
    "encoders['deviations'] = y_columns\n",
    "# Save encoding/ decoding key as .pkl\n",
    "joblib.dump(encoders, \"encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor encoding and saving â€” quick literal fix\n",
    "device = torch.device(\"cpu\") # store to cpu\n",
    "dataset_prep = PrefixDataset(# datset\n",
    "                             df_train=train_df,\n",
    "                             df_val=val_df,\n",
    "                             df_test=test_df,\n",
    "                             # column values\n",
    "                             activity_col='activities',\n",
    "                             resource_col='resources',\n",
    "                             month_col='months',\n",
    "                             trace_cols=[],\n",
    "                             y_cols=encoders['deviations'],\n",
    "                             label_strategy = \"collective\")\n",
    "\n",
    "# Encode to tensor datsets and save files\n",
    "train_set, val_set, test_set = dataset_prep.tensor_datset_encoding(device=device)\n",
    "dataset_prep.save_datasets(train_dataset=train_set, val_dataset=val_set, test_dataset=test_set, save_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315845b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = dataset_prep.load_datasets(\".\")\n",
    "print(train_set.tensors)\n",
    "print(val_set.tensors)\n",
    "print(test_set.tensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_controlled_proactive_conformance_chec-7RbHgjHV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
