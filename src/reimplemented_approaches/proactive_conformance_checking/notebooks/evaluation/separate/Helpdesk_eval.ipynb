{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae75a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from joblib import load\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "sys.path.insert(0, '../../../../..')\n",
    "sys.path.insert(0, '../../../../../..')\n",
    "\n",
    "from reimplemented_approaches.proactive_conformance_checking.data_prep_split_encode import PrefixDataset\n",
    "from reimplemented_approaches.proactive_conformance_checking.models import LSTMSeparateIDP\n",
    "from reimplemented_approaches.proactive_conformance_checking.evaluation import PredictionResults, MetricsSep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b7df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: ../../data_preparation/Helpdesk/separate/\n",
      "Models dir: ../../training/Helpdesk/separate\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../../data_preparation/Helpdesk/separate/\"\n",
    "models_dir = Path(\"../../training/Helpdesk/separate/\")\n",
    "\n",
    "print(f\"Data dir: {data_dir}\")\n",
    "print(f\"Models dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab9a012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation labels (6): [\"('>>', 'Assign seriousness')\", \"('Create SW anomaly', '>>')\", \"('Require upgrade', '>>')\", \"('Resolve ticket', '>>')\", \"('Take in charge ticket', '>>')\", \"('Wait', '>>')\"]\n"
     ]
    }
   ],
   "source": [
    "_, _, test_set_dict = PrefixDataset.load_datasets(save_path=data_dir)\n",
    "encoders = load(data_dir + \"/encoders.pkl\")\n",
    "\n",
    "deviations = encoders.get(\"deviations\")\n",
    "\n",
    "deviation_labels = sorted(test_set_dict.keys())\n",
    "\n",
    "print(f\"Deviation labels ({len(deviation_labels)}): {deviation_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e6b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Evaluating on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0eb17e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating label: ('>>', 'Assign seriousness') ===\n",
      "\n",
      "=== Evaluating label: ('Create SW anomaly', '>>') ===\n",
      "\n",
      "=== Evaluating label: ('Require upgrade', '>>') ===\n",
      "\n",
      "=== Evaluating label: ('Resolve ticket', '>>') ===\n",
      "\n",
      "=== Evaluating label: ('Take in charge ticket', '>>') ===\n",
      "\n",
      "=== Evaluating label: ('Wait', '>>') ===\n"
     ]
    }
   ],
   "source": [
    "metrics_summary = {}\n",
    "\n",
    "for label in deviation_labels:\n",
    "    print(f\"\\n=== Evaluating label: {label} ===\")\n",
    "    \n",
    "    test_set = test_set_dict[label]\n",
    "    \n",
    "    model_path = models_dir / f\"LSTM_separate_IDP_{label}.pkl\"\n",
    "    \n",
    "    model = LSTMSeparateIDP.load(str(model_path), device=device)\n",
    "    \n",
    "    pr = PredictionResults(model=model, test_set=test_set, mode='separate')\n",
    "    probs, preds, targets = pr.get_predictions_targets()\n",
    "    # print(probs)\n",
    "    # print(preds)\n",
    "    # print(targets)\n",
    "    \n",
    "    m = MetricsSep(preds=preds, targets=targets)\n",
    "    \n",
    "    res_dev = m.precision_recall_dev()\n",
    "    \n",
    "    res_no_dev = m.precision_recall_no_dev()\n",
    "    \n",
    "    metrics_summary[label] = {\"macro_dev\": res_dev,\n",
    "                              \"macro_no_dev\": res_no_dev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb29502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average precision dev:  0.06446474773624894\n",
      "Macro average recall dev:  0.35385668276972626\n",
      "\n",
      "\n",
      "Macro average precision no dev:  0.9896694264336068\n",
      "Macro average recall no dev:  0.8816703569306653\n"
     ]
    }
   ],
   "source": [
    "macro_precision_dev = 0.0\n",
    "macro_precision_no_dev = 0.0\n",
    "macro_recall_dev = 0.0\n",
    "macro_recall_no_dev = 0.0\n",
    "\n",
    "for label, results in metrics_summary.items():    \n",
    "    # print(f\"\\nLabel: {label}\")\n",
    "    # print(\"deviation metrics:\", results[\"macro_dev\"])\n",
    "    # print(\"no-deviation metrics:\", results[\"macro_no_dev\"])\n",
    "    \n",
    "    macro_precision_dev += results[\"macro_dev\"].get('precision')\n",
    "    macro_recall_dev += results[\"macro_dev\"].get('recall')\n",
    "\n",
    "    macro_precision_no_dev += results[\"macro_no_dev\"].get('precision')\n",
    "    macro_recall_no_dev += results[\"macro_no_dev\"].get('recall')\n",
    "    \n",
    "print(\"Macro average precision dev: \", macro_precision_dev/ len(list(metrics_summary.keys())))\n",
    "print(\"Macro average recall dev: \", macro_recall_dev/ len(list(metrics_summary.keys())))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Macro average precision no dev: \", macro_precision_no_dev/ len(list(metrics_summary.keys())))\n",
    "print(\"Macro average recall no dev: \", macro_recall_no_dev/ len(list(metrics_summary.keys())))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_controlled_proactive_conformance_chec-7RbHgjHV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
